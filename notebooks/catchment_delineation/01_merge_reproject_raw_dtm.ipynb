{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b5a1bc-db26-4c46-b142-f2d23e1609d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import rioxarray as rio\n",
    "from joblib import Parallel, delayed\n",
    "from rasterio.enums import Resampling\n",
    "from rioxarray.merge import merge_arrays\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from WBT.whitebox_tools import WhiteboxTools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aee1b0-5df2-4528-a6f4-3277ce401a18",
   "metadata": {},
   "source": [
    "# Reprojecting and merging the Norwegian national 10 m terrain dataset\n",
    "\n",
    "***Note:** This notebook must be run on a machine with plenty of RAM. If the data are processed as 16-bit integers, peak memory consumption is around 120 GB. For 32-bit floats (recommended) it's 240 GB, which will crash the \"El Gordo\" machine. The 1 TB machine handles everything easily.*\n",
    "\n",
    "For hydrological calculations we need a good quality DEM. Kartverket's **10 m DTM** is probably the best choice in most cases: the 1 m data is not available everywhere and is unnecessarily detailed, and a DTM is better than a DOM for hydrology (see [here](https://hoydedata.no/LaserInnsyn/help_no/index.htm?context=130)). The 10 m DTM can be downloaded in 50 x 50 km tiles, split across three UTM zones:\n",
    "\n",
    " * [UTM zone 32](https://kartkatalog.geonorge.no/metadata/dtm-10-terrengmodell-utm32/fd851873-f363-46f9-9fc6-bb1b403575df)\n",
    " * [UTM zone 33](https://kartkatalog.geonorge.no/metadata/dtm-10-terrengmodell-utm33/dddbb667-1303-4ac5-8640-7ec04c0e3918)\n",
    " * [UTM zone 35](https://kartkatalog.geonorge.no/metadata/dtm-10-terrengmodell-utm35/294c21ca-eb83-49b9-8861-bb1595ce8768)\n",
    " \n",
    "This notebook first reprojects each tile to UTM Zone 33N (EPSG 25833) and merges them again into a single dataset for the entire country. Arrays are also compressed using the LZW algorithm to save space.\n",
    "\n",
    "The national 10 m dataset for the whole country is then downsampled using bilinear interpolation to create 20 m and 40 m resolution versions. These will be useful for testing and they should also be sufficient for catchment delineation by themselves.\n",
    "\n",
    "**Note:** a **conformal projection** (such as EPSG 3395; WGS 84 World Mercator) is best for watershed delineation, but UTM Zone 33N will probably be good enough here.\n",
    "\n",
    "**Note 2:** I originally tried converting all the grids to 16-bit integer type as, with compression, this dramatically reduces disk space and memory requirements. However, it also leads to difficulties resolving flow direction flat areas, and it's ultimately more trouble than it's worth. I recommend preserving the original 32-bit floats where possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65cd171-985f-4c36-b58c-1a4abb63a5e0",
   "metadata": {},
   "source": [
    "## 1. Adding large files to the JupyterHub\n",
    "\n",
    "Usually it is possible to upload files to the Hub by dragging and dropping from your local file system via your browser. However, for very large files (multiple GB), a faster and more robust solution is to use `gdown` and Google Drive.\n",
    "\n",
    "The 10 m DTM tiles for each UTM zone are large. First, zip the files you want to upload (make sure you create a .zip archive and not a .7z). Then upload the zip to your Google Drive and make the file public (`Sharing > Anyone with the link can view`) and copy the sharable link. From a terminal on JupyterHub, cd into the folder where you want to add the file and run the following:\n",
    "\n",
    "    gdown SHARABLE_LINK_COPIED_FROM_GOOGLE_DRIVE --fuzzy\n",
    "    \n",
    "This should quickly add the data to the Hub. You can unzip the file from the command line using `unzip filename.zip`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5061abdd-97c3-4c91-93be-31a885efe686",
   "metadata": {},
   "source": [
    "## 2. User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7986936-a9d2-4f5f-ac83-f85c103a528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTM zones to process\n",
    "zone_list = [32, 33, 35]\n",
    "\n",
    "# Properties for mosaic\n",
    "dst_crs = \"EPSG:25833\"\n",
    "bbox = (-80000, 6440000, 1122000, 7950000)  # xmin, ymin, xmax, ymax\n",
    "dst_fold = f\"/home/jovyan/shared/01_datasets/spatial/dtm10_proj_utm33\"\n",
    "no_data_val = -32767\n",
    "dst_dtype = \"float32\"  # Rasterio dtypes: https://test2.biogeo.ucdavis.edu/rasterio/_modules/rasterio/dtypes.html\n",
    "dst_res = 10\n",
    "\n",
    "# Set values <= 0 to NaN?\n",
    "neg_to_nan = False\n",
    "\n",
    "# Rasters to create\n",
    "nor_10m_dtm = r\"/home/jovyan/shared/01_datasets/spatial/dtm_merged_utm33/dtm_10m/norway_kartverket_10m_dtm_utm_z33.tif\"\n",
    "nor_20m_dtm = r\"/home/jovyan/shared/01_datasets/spatial/dtm_merged_utm33/dtm_20m/norway_kartverket_20m_dtm_utm_z33.tif\"\n",
    "nor_40m_dtm = r\"/home/jovyan/shared/01_datasets/spatial/dtm_merged_utm33/dtm_40m/norway_kartverket_40m_dtm_utm_z33.tif\"\n",
    "\n",
    "# Number of workers if choose to run section 3 in parallel\n",
    "n_jobs = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2bdbe4-a05d-48fc-8f2f-a169869f53bb",
   "metadata": {},
   "source": [
    "## 3. Reproject to UTM Zone 33N\n",
    "\n",
    "The cell below processes data sequentially. Good for machines with \"smaller\" amounts of memory (e.g. 240 GB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051fb244-7da9-47e0-a955-74956e659b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for zone in tqdm(zone_list, desc=\"Looping over zones\"):\n",
    "#     search_path = f\"/home/jovyan/shared/01_datasets/spatial/dtm_10_raw/utm_{zone}/*.tif\"\n",
    "#     flist = sorted(glob.glob(search_path))\n",
    "#     dst_list = [os.path.join(dst_fold, os.path.split(fname)[1]) for fname in flist]\n",
    "\n",
    "#     for idx, src_path in enumerate(tqdm(flist, desc=\"Looping over files\")):\n",
    "#         dst_path = dst_list[idx]\n",
    "#         rds = rio.open_rasterio(src_path, mask_and_scale=True)\n",
    "\n",
    "#         if neg_to_nan:\n",
    "#             rds = rds.where(rds > 0)\n",
    "\n",
    "#         rds.rio.write_nodata(no_data_val, encoded=True, inplace=True)\n",
    "#         rds = rds.rio.reproject(\n",
    "#             dst_crs,\n",
    "#             resolution=dst_res,\n",
    "#             nodata=no_data_val,\n",
    "#             resampling=Resampling.bilinear,\n",
    "#         )\n",
    "#         rds.rio.to_raster(dst_path, compress=\"lzw\", BIGTIFF=\"IF_SAFER\", dtype=dst_dtype)\n",
    "#         rds.close()\n",
    "#         del rds\n",
    "#         gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92694e2-5650-4791-93eb-f26bd00b07c6",
   "metadata": {},
   "source": [
    "On machines with lots of memory (e.g. 1 TB), the following parallel version is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e817fb-be76-4a14-a9b9-4a9dc3989895",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def reproject(src_path, dst_path, neg_to_nan, no_data_val, dst_crs, dst_res, dst_dtype):\n",
    "    \"\"\" \"\"\"\n",
    "    rds = rio.open_rasterio(src_path, mask_and_scale=True)\n",
    "\n",
    "    if neg_to_nan:\n",
    "        rds = rds.where(rds > 0)\n",
    "\n",
    "    rds.rio.write_nodata(no_data_val, encoded=True, inplace=True)\n",
    "    rds = rds.rio.reproject(\n",
    "        dst_crs,\n",
    "        resolution=dst_res,\n",
    "        nodata=no_data_val,\n",
    "        resampling=Resampling.bilinear,\n",
    "    )\n",
    "    rds.rio.to_raster(dst_path, compress=\"lzw\", BIGTIFF=\"IF_SAFER\", dtype=dst_dtype)\n",
    "    rds.close()\n",
    "    del rds\n",
    "    gc.collect()\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "for zone in tqdm(zone_list, desc=\"Looping over zones\"):\n",
    "    search_path = f\"/home/jovyan/shared/01_datasets/spatial/dtm_10_raw/utm_{zone}/*.tif\"\n",
    "    flist = sorted(glob.glob(search_path))\n",
    "    dst_list = [os.path.join(dst_fold, os.path.split(fname)[1]) for fname in flist]\n",
    "\n",
    "    Parallel(n_jobs=n_jobs)(\n",
    "        delayed(reproject)(\n",
    "            src_path,\n",
    "            dst_list[idx],\n",
    "            neg_to_nan,\n",
    "            no_data_val,\n",
    "            dst_crs,\n",
    "            dst_res,\n",
    "            dst_dtype,\n",
    "        )\n",
    "        for idx, src_path in enumerate(flist)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786ba8ca-01b3-4aa3-b00d-4860ad661c54",
   "metadata": {},
   "source": [
    "## 4. Merge to a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ef7e0-4e78-482a-aaac-aed733971638",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "search_path = f\"{dst_fold}/*.tif\"\n",
    "flist = sorted(glob.glob(search_path))\n",
    "print(len(flist), \"files to process.\")\n",
    "\n",
    "print(\"Opening files...\")\n",
    "srcs = [rio.open_rasterio(fpath, mask_and_scale=True, cache=False) for fpath in flist]\n",
    "\n",
    "print(\"Merging tiles...\")\n",
    "rds = merge_arrays(srcs, bounds=bbox, res=dst_res)\n",
    "\n",
    "print(\"Saving...\")\n",
    "rds.rio.write_nodata(no_data_val, inplace=True)\n",
    "rds.rio.to_raster(\n",
    "    nor_10m_dtm,\n",
    "    compress=\"lzw\",\n",
    "    BIGTIFF=\"YES\",\n",
    "    tiled=True,\n",
    "    dtype=dst_dtype,\n",
    ")\n",
    "srcs = [src.close() for src in srcs]\n",
    "rds.close()\n",
    "del srcs, rds\n",
    "gc.collect()\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5781752d-31f5-465f-a274-47a03e6b015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Alternative using WBT. May be more memory efficient,\n",
    "# # but not yet tested as the above seems to work\n",
    "# wbt = WhiteboxTools()\n",
    "# wbt.set_verbose_mode(False)\n",
    "# wbt.set_compress_rasters(True)\n",
    "# wbt.set_working_dir(dst_fold)\n",
    "\n",
    "# wbt.mosaic(\n",
    "#     nor_10m_dtm,\n",
    "#     inputs=None,\n",
    "#     method=\"bilinear\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803c6d88-146a-495e-949f-616ebc83b285",
   "metadata": {},
   "source": [
    "## 5. Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0586ba19-a3fd-492c-88a6-2486db734ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Downsampling to 20m...\")\n",
    "rds = rio.open_rasterio(nor_10m_dtm, mask_and_scale=True, cache=False)\n",
    "upscale_factor = 0.5\n",
    "width = int(rds.rio.width * upscale_factor)\n",
    "height = int(rds.rio.height * upscale_factor)\n",
    "\n",
    "rds = rds.rio.reproject(\n",
    "    rds.rio.crs,\n",
    "    shape=(height, width),\n",
    "    resampling=Resampling.bilinear,\n",
    ")\n",
    "\n",
    "rds.rio.to_raster(\n",
    "    nor_20m_dtm, compress=\"lzw\", BIGTIFF=\"IF_SAFER\", tiled=True, dtype=dst_dtype\n",
    ")\n",
    "rds.close()\n",
    "del rds\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee77108-0ba8-4c25-8318-84722bfd70f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Downsampling to 40m...\")\n",
    "rds = rio.open_rasterio(nor_10m_dtm, mask_and_scale=True, cache=False)\n",
    "upscale_factor = 0.25\n",
    "width = int(rds.rio.width * upscale_factor)\n",
    "height = int(rds.rio.height * upscale_factor)\n",
    "\n",
    "rds = rds.rio.reproject(\n",
    "    rds.rio.crs,\n",
    "    shape=(height, width),\n",
    "    resampling=Resampling.bilinear,\n",
    ")\n",
    "\n",
    "rds.rio.to_raster(\n",
    "    nor_40m_dtm, compress=\"lzw\", BIGTIFF=\"IF_SAFER\", tiled=True, dtype=dst_dtype\n",
    ")\n",
    "rds.close()\n",
    "del rds\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
