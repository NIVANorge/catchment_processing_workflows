{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16b5a1bc-db26-4c46-b142-f2d23e1609d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import rioxarray as rio\n",
    "from joblib import Parallel, delayed\n",
    "from rasterio.enums import Resampling\n",
    "from rioxarray.merge import merge_arrays\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aee1b0-5df2-4528-a6f4-3277ce401a18",
   "metadata": {},
   "source": [
    "# Reprojecting and merging the Norwegian national 10 m terrain dataset\n",
    "\n",
    "***Note:** This notebook must be run on a machine with plenty of RAM. If the data are processed as 16-bit integers, peak memory consumption is around 120 GB. For 32-bit floats (recommended) it's 240 GB, which will crash the \"El Gordo\" machine. The 1 TB machine handles everything easily.*\n",
    "\n",
    "For hydrological calculations we need a good quality DEM. Kartverket's **10 m DTM** is probably the best choice in most cases: the 1 m data is not available everywhere and is unnecessarily detailed, and a DTM is better than a DOM for hydrology (see [here](https://hoydedata.no/LaserInnsyn/help_no/index.htm?context=130)). The 10 m DTM can be downloaded in 50 x 50 km tiles from the Høydedata website (`Eksport > Landsdekkende > DTM10`). Data for the entire country are available as 254 tiles in UTM Zone 33 (~18 GB compressed).\n",
    " \n",
    "This notebook merges the tiles into a single dataset for the entire country. Arrays are also compressed using the LZW algorithm to save space.\n",
    "\n",
    "The national 10 m dataset for the whole country is then downsampled using bilinear interpolation to create 20 m and 40 m resolution versions. These will be useful for testing and they should also be sufficient for catchment delineation by themselves.\n",
    "\n",
    "**Note:** a **conformal projection** (such as EPSG 3395; WGS 84 World Mercator) is best for watershed delineation, but UTM Zone 33N will probably be good enough here.\n",
    "\n",
    "**Note 2:** I originally tried converting all the grids to 16-bit integer type as, with compression, this dramatically reduces disk space and memory requirements. However, it also leads to difficulties resolving flow directions flat areas, and it's ultimately more trouble than it's worth. I recommend preserving the original 32-bit floats where possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65cd171-985f-4c36-b58c-1a4abb63a5e0",
   "metadata": {},
   "source": [
    "## 1. Adding large files to the JupyterHub\n",
    "\n",
    "### 1.1. Using `wget`\n",
    "\n",
    "At the time of writing, the Høydedata website provides a direct link to a zip archive containing all times in UTM zone 33. This can be downloaded easily by `cd`-ing into the download folder and running\n",
    "\n",
    "    wget https://hoydedata.no/LaserServices/REST/DownloadFile.ashx?id=54 -O dtm_10m_utm_33.zip\n",
    "    \n",
    "This can then be unzipped using `unzip dtm_10m_utm_33.zip`.\n",
    "\n",
    "### 1.2. Using `gdown`\n",
    "\n",
    "(This was useful before I discovered Kartverket's direct link).\n",
    "\n",
    "Usually it is possible to upload files to the Hub by dragging and dropping from your local file system via your browser. However, for very large files (multiple GB), a faster and more robust solution is to use `gdown` and Google Drive.\n",
    "\n",
    "The 10 m DTM tiles for each UTM zone are large. First, zip the files you want to upload (make sure you create a .zip archive and not a .7z). Then upload the zip to your Google Drive and make the file public (`Sharing > Anyone with the link can view`) and copy the sharable link. From a terminal on JupyterHub, cd into the folder where you want to add the file and run the following:\n",
    "\n",
    "    gdown SHARABLE_LINK_COPIED_FROM_GOOGLE_DRIVE --fuzzy\n",
    "    \n",
    "This should quickly add the data to the Hub. You can unzip the file from the command line using `unzip filename.zip`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5061abdd-97c3-4c91-93be-31a885efe686",
   "metadata": {},
   "source": [
    "## 2. User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7986936-a9d2-4f5f-ac83-f85c103a528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Properties for mosaic\n",
    "dst_crs = \"EPSG:25833\"\n",
    "bbox = (-80000, 6440000, 1122000, 7950000)  # xmin, ymin, xmax, ymax\n",
    "no_data_val = -32767\n",
    "dst_dtype = \"float32\"  # Rasterio dtypes: https://test2.biogeo.ucdavis.edu/rasterio/_modules/rasterio/dtypes.html\n",
    "dst_res = 10\n",
    "\n",
    "# Set values <= 0 to NaN?\n",
    "neg_to_nan = False\n",
    "\n",
    "# Rasters to create\n",
    "nor_10m_dtm = r\"/home/jovyan/shared/01_datasets/spatial/dtm_merged_utm33/dtm_10m/norway_kartverket_10m_dtm_utm_z33.tif\"\n",
    "nor_20m_dtm = r\"/home/jovyan/shared/01_datasets/spatial/dtm_merged_utm33/dtm_20m/norway_kartverket_20m_dtm_utm_z33.tif\"\n",
    "nor_40m_dtm = r\"/home/jovyan/shared/01_datasets/spatial/dtm_merged_utm33/dtm_40m/norway_kartverket_40m_dtm_utm_z33.tif\"\n",
    "\n",
    "# Number of workers if choose to run section 3 in parallel\n",
    "n_jobs = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786ba8ca-01b3-4aa3-b00d-4860ad661c54",
   "metadata": {},
   "source": [
    "## 3. Merge to a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d56ef7e0-4e78-482a-aaac-aed733971638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254 files to process.\n",
      "Opening files...\n",
      "Merging tiles...\n",
      "Saving...\n",
      "Done.\n",
      "CPU times: user 14min 48s, sys: 3min 35s, total: 18min 24s\n",
      "Wall time: 20min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "search_path = \"/home/jovyan/shared/01_datasets/spatial/dtm_10_raw/utm_33/*.tif\"\n",
    "flist = sorted(glob.glob(search_path))\n",
    "print(len(flist), \"files to process.\")\n",
    "\n",
    "print(\"Opening files...\")\n",
    "srcs = [rio.open_rasterio(fpath, mask_and_scale=True, cache=False) for fpath in flist]\n",
    "\n",
    "print(\"Merging tiles...\")\n",
    "rds = merge_arrays(srcs, bounds=bbox, res=dst_res)\n",
    "\n",
    "print(\"Saving...\")\n",
    "rds.rio.write_nodata(no_data_val, inplace=True)\n",
    "rds.rio.to_raster(\n",
    "    nor_10m_dtm,\n",
    "    compress=\"lzw\",\n",
    "    BIGTIFF=\"YES\",\n",
    "    tiled=True,\n",
    "    dtype=dst_dtype,\n",
    ")\n",
    "srcs = [src.close() for src in srcs]\n",
    "rds.close()\n",
    "del srcs, rds\n",
    "gc.collect()\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803c6d88-146a-495e-949f-616ebc83b285",
   "metadata": {},
   "source": [
    "## 4. Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0586ba19-a3fd-492c-88a6-2486db734ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampling to 20m...\n",
      "CPU times: user 16min 13s, sys: 4min 31s, total: 20min 45s\n",
      "Wall time: 20min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Downsampling to 20m...\")\n",
    "rds = rio.open_rasterio(nor_10m_dtm, mask_and_scale=True, cache=False)\n",
    "upscale_factor = 0.5\n",
    "width = int(rds.rio.width * upscale_factor)\n",
    "height = int(rds.rio.height * upscale_factor)\n",
    "\n",
    "rds = rds.rio.reproject(\n",
    "    rds.rio.crs,\n",
    "    shape=(height, width),\n",
    "    resampling=Resampling.bilinear,\n",
    ")\n",
    "\n",
    "rds.rio.to_raster(\n",
    "    nor_20m_dtm, compress=\"lzw\", BIGTIFF=\"IF_SAFER\", tiled=True, dtype=dst_dtype\n",
    ")\n",
    "rds.close()\n",
    "del rds\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee77108-0ba8-4c25-8318-84722bfd70f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampling to 40m...\n",
      "CPU times: user 11min 24s, sys: 3min 50s, total: 15min 15s\n",
      "Wall time: 15min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Downsampling to 40m...\")\n",
    "rds = rio.open_rasterio(nor_10m_dtm, mask_and_scale=True, cache=False)\n",
    "upscale_factor = 0.25\n",
    "width = int(rds.rio.width * upscale_factor)\n",
    "height = int(rds.rio.height * upscale_factor)\n",
    "\n",
    "rds = rds.rio.reproject(\n",
    "    rds.rio.crs,\n",
    "    shape=(height, width),\n",
    "    resampling=Resampling.bilinear,\n",
    ")\n",
    "\n",
    "rds.rio.to_raster(\n",
    "    nor_40m_dtm, compress=\"lzw\", BIGTIFF=\"IF_SAFER\", tiled=True, dtype=dst_dtype\n",
    ")\n",
    "rds.close()\n",
    "del rds\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
